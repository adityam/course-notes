<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-05-31">
<meta name="description" content="ECES 506 (Stochastic Control and Decision Theory)">

<title>Course Notes - 9&nbsp; Reward Shaping</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../mdps/inf-horizon.html" rel="next">
<link href="../mdps/power-delay-tradeoff.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      IND: "\\mathbb{I}",
      ONES: "\\mathbb{1}",
      reals: "\\mathbb{R}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      NORM: ["\\left\\lVert #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert #1 \\right\\rvert", 1]
    },
    autoload: {
      color: ['color'],
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../stochastic-control/index.html">
 <span class="menu-text">Stochastic Control</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../multi-agent-systems/index.html">
 <span class="menu-text">Multi-Agent Systems</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reward Shaping</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">index.html</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Static Stochastic Optimization</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/newsvendor.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The newsvendor problem</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Markov decision processes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/gambling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Optimal gambling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inventory Management</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/monotone-mdps.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/power-delay-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/reward-shaping.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reward Shaping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inf-horizon.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mdp-algorithms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">MDP algorithms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management-revisited.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Inventory management (revisted)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mobile-edge-computing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Service Migration in Mobile edge computing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/computational-complexity-vi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Computational complexity of value interation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/linear-programming.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Linear programming formulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/lipschitz-mdps.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Approximate Dynamic Programming</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Risk sensitive Markov decision processes</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Partially observable Markov decision processes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Reinforcement Learning</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Linear Quadratic Control</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Probability Appendix</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/sub-gaussian.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Sub-Gaussian random variables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">Linear Algebra Appendix</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/postive-definite-matrix.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Positive definite matrices</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/svd.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Singular value decomposition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/rkhs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Reproducing Kernel Hilbert Space</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">Assignments</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/01.html" class="sidebar-item-text sidebar-link">Assignment 1</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#generalization-to-discounted-models" id="toc-generalization-to-discounted-models" class="nav-link active" data-scroll-target="#generalization-to-discounted-models"><span class="toc-section-number">9.1</span>  Generalization to discounted models</a></li>
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="toc-section-number">9.2</span>  Examples</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Reward Shaping</span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 31, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="callout-note callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<i class="bi bi-journal-text text-primary"></i> Summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>What are the conditions under which two MDPs which have the same dynamics but different cost functions have the same optimal policy? This is an important question in reinforcement learning (where one often <em>shapes</em> the reward function to speed up learning) and inverse reinforcement learning (where one learns the reward function from the behavior of an expert). The following result provides a complete answer to this question. These results are typically established for inifinte horizon models. However, in my opinion, it is conceptually simpler to start with the finite horizon model.</p>
</div>
</div>
<div class="page-columns page-full"><p>Let <span class="math inline">\(M^1\)</span> and <span class="math inline">\(M^2\)</span> denote two MDPs on the same state space <span class="math inline">\(\ALPHABET S\)</span> and action space <span class="math inline">\(\ALPHABET A\)</span>. Both MDPs have the same dynamics <span class="math inline">\(P = (P_1, \dots, P_T)\)</span>, but different cost functions <span class="math inline">\(c^1 = (c^1_1, \dots, c^1_T)\)</span> and <span class="math inline">\(c^2 = (c^2_1, \dots, c^2_T)\)</span>. We assume that for <span class="math inline">\(t \in \{1, \dots, T-1\}\)</span>, the per-step cost is a function of the current state, current action, and next state (see <a href="../mdp-functional#cost-depends-on-next-state">cost depending on next state</a>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and for <span class="math inline">\(t = T\)</span>, the per-step cost function is just a function of the current state.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;We choose the cost to depend on the next state only for convenience of analysis. The result of <a href="#thm-reward-shaping">Theorem&nbsp;<span>9.1</span></a> can be established for models where the cost depends only on the per-step cost by replacing property&nbsp;2 in <a href="#thm-reward-shaping">Theorem&nbsp;<span>9.1</span></a> by <span class="math display">\[ c^2_t(s,a) = c^1_t(s,a) + \sum_{s' \in \ALPHABET S} P_t(s'|s,a) Φ_{t+1}(s') -
Φ_t(s).\]</span></p></li></div></div>
<div id="thm-reward-shaping" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.1 </strong></span>Suppose the cost functions in MDPs <span class="math inline">\(M^1\)</span> and <span class="math inline">\(M^2\)</span> are related as follows:</p>
<ol type="1">
<li><p>For <span class="math inline">\(t = T\)</span>, <span class="math display">\[ c^2_T(s) = c^1_T(s) - Φ_T(s).  \]</span></p></li>
<li><p>For <span class="math inline">\(t \in \{1, \dots, T-1\}\)</span>, <span class="math display">\[ c^2_t(s,a,s_{+}) = c^1_t(s,a,s_{+}) +  Φ_{t+1}(s_{+}) - Φ_t(s). \]</span></p></li>
</ol>
<p>Then, for any policy <span class="math inline">\(π\)</span>, <span class="math display">\[\begin{equation}\label{eq:result}
    Q^{\pi,2}_t(s,a) = Q^{\pi,1}_t(s,a) - Φ_t(s)
    \quad\text{and}\quad
    V^{\pi,2}_t(s) = V^{\pi,1}_t(s) - Φ_t(s).
\end{equation}\]</span></p>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Sign of potential function
</div>
</div>
<div class="callout-body-container callout-body">
<p>The sign of the potential function is irrelevant. So, we could also have written <span class="math display">\[ c^2_t(s,a,s_{+}) = c^1_t(s,a,s_{+}) +  Φ_t(s) - Φ_{t+1}(s_{+}) \]</span> and argued that <span class="math display">\[  V^{\pi,2}_t(s) = V^{\pi,1}_t(s) + Φ_t(s).\]</span></p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We prove the result by backward induction. First note that <span class="math display">\[
  V^{\pi,2}_T(s) = c^2_T(s) = c^1_T(s) - Φ_T(s) = V^{\pi,1}_T(s) - Φ_T(s).
\]</span> This forms the basis of induction. Now suppose that \eqref{eq:result} holds for time <span class="math inline">\(t+1\)</span>. Now consider <span class="math display">\[\begin{align*}
Q^{\pi,2}_t(s,a) &amp;= \EXP[ c^2_t(s,a,S_{t+1}) + V^{\pi,2}_{t+1}(S_{t+1}) \mid S_t
= s, a ]
\\
&amp;\stackrel{(a)}= \EXP[ c^1_t(s,a,S_{t+1}) - Φ_t(s) + Φ_{t+1}(S_{t+1}) \\
&amp;\qquad + V^{\pi,1}_{t+1}(S_{t+1}) - Φ_{t+1}(S_{t+1}) \mid S_t = s, A_t = a ] \\
&amp;= \EXP[ c^1_t(s,a,S_{t+1}) - Φ_t(s) + V^1_{t+1}(S_{t+1}) \mid
S_t = s, A_t = a] \\
&amp;= Q^{\pi,1}_t(s,a) - Φ_t(s),
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from property 2 and the induction hypothesis.</p>
<p>Now, <span class="math display">\[ \begin{align*}
  V^{\pi,2}_t(s) &amp;= Q^{\pi,2}_t(s,\pi(s)) \\
  &amp;= Q^{\pi,1}_t(s,\pi(s) - Φ_t(s) \\
  &amp;= V^{\pi,1}_t(s) - Φ_t(s).
\end{align*}\]</span></p>
<p>This proves the induction step.</p>
</div>
</div>
</div>
<p>By almost an analogous argument, we can show that the optimal value functions also satisfy a similar relationship.</p>
<div id="cor-reward-shaping" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 9.1 </strong></span>Under conditions of <a href="#thm-reward-shaping">Theorem&nbsp;<span>9.1</span></a>, <span class="math display">\[\begin{equation}\label{eq:result-opt}
      Q^{2}_t(s,a) = Q^{1}_t(s,a) - Φ_t(s)
      \quad\text{and}\quad
      V^{2}_t(s) = V^{1}_t(s) - Φ_t(s).
  \end{equation}\]</span></p>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Advantage function
</div>
</div>
<div class="callout-body-container callout-body">
<p>The advantage (or benefit) function given by <span class="math display">\[ B_t(s,a) := Q_t(s,a) - V_t(s) \]</span> measures the relative cost of choosing action <span class="math inline">\(a\)</span> over the optimal action. An implication of \eqref{eq:result-opt} is that reward shaping does not change the advantage function!</p>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Remark
</div>
</div>
<div class="callout-body-container callout-body">
<p>Another implication of <a href="#thm-reward-shaping">Theorem&nbsp;<span>9.1</span></a> and <a href="#cor-reward-shaping">Corollary&nbsp;<span>9.1</span></a> is that for any policy <span class="math inline">\(π\)</span>, <span class="math display">\[ V^{\pi,2}_t(s) - V^{2}_t(s) = V^{\pi,1}_t(s) - V^1_t(s). \]</span> Thus, reward shaping also preserves near-optimality; i.e., if a policy is approximately optimal in model <span class="math inline">\(M^1\)</span>, then it is approximately optimal in model <span class="math inline">\(M^2\)</span> as well.</p>
</div>
</div>
<section id="generalization-to-discounted-models" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="generalization-to-discounted-models"><span class="header-section-number">9.1</span> Generalization to discounted models</h2>
<p>Now consider a finite horizon discounted cost problem, where the performance of a policy <span class="math inline">\(π\)</span> is given by <span class="math display">\[
J(π) = \EXP\Bigl[ \sum_{t=1}^{T-1} γ^{t-1} c_t(S_t, A_t) + γ^T c_T(S_T)
       \Bigr].
\]</span> As argued in <a href="intro.html#discounted-cost">the introduction to discounted models</a>, the dynamic prgram for this case is given by</p>
<p><span class="math display">\[ V_{T}(s) = c_T(s) \]</span> and for <span class="math inline">\(t \in \{T-1, \dots, 1\}\)</span>: <span class="math display">\[ \begin{align*}
  Q_t(s,a) &amp;= c(s,a) + γ \EXP[ V_{t+1}(S_{t+1}) | S_t = s, A_t = a ], \\
  V_t(s) &amp;= \min_{a \in \ALPHABET A} Q_t(s,a).
\end{align*} \]</span></p>
<p>For such models, we have the following.</p>
<div id="cor-reward-shaping-discounted" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 9.2 </strong></span>For discounted cost models, the results of <a href="#thm-reward-shaping">Theorem&nbsp;<span>9.1</span></a> and <a href="#cor-reward-shaping">Corollary&nbsp;<span>9.1</span></a> continue to hold if condition 2 is replaced by</p>
<ol start="2" type="1">
<li><p>For <span class="math inline">\(t \in \{1, \dots, T-1\}\)</span>,</p>
<p><span class="math display">\[ c^2_t(s,a,s_{+}) = c^1_t(s,a,s_{+}) + γ Φ_{t+1}(s_{+}) - Φ_t(s). \]</span></p></li>
</ol>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Infinite horizon models
</div>
</div>
<div class="callout-body-container callout-body">
<p>If the cost function is time homogeneous, <a href="#cor-reward-shaping-discounted">Corollary&nbsp;<span>9.2</span></a> extends naturally to infinite horizon models with a time-homogeneous potential function. A remarkable feature is that if the potential function is chosen as the value function, i.e., <span class="math inline">\(Φ(s) = V(s)\)</span>, then the value function of the modified cost <span class="math inline">\(\tilde c(s,a,s_{+})\)</span> is zero!</p>
</div>
</div>
</section>
<section id="examples" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="examples"><span class="header-section-number">9.2</span> Examples</h2>
<p>As an example of reward shaping, see the notes on <a href="../../inf-mdp/inventory-management">inventory management</a>. Also see the notes on <a href="../../inf-mdp/martingale-approach">martingale approach to stochastic control</a> for an iteresting relationship between reward shaping and martingales.</p>
</section>
<section id="notes" class="level1 unnumbered">
<h1 class="unnumbered">Notes</h1>
<p>The idea of <em>reward shaping</em> was proposed by <span class="citation" data-cites="Skinner1938">Skinner (<a href="../references.html#ref-Skinner1938" role="doc-biblioref">1938</a>)</span> to synthesize complex behavior by guiding animals to perform simple functions (see <a href="https://en.wikipedia.org/wiki/Operant_conditioning_chamber">:Skinner’s Box Experiment</a>). The formal description of reward shaping comes from <span class="citation" data-cites="Porteus1975">Porteus (<a href="../references.html#ref-Porteus1975" role="doc-biblioref">1975</a>)</span>, who established a result similar to <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span>, and called it the transformation method. <span class="citation" data-cites="Porteus1975">Porteus (<a href="../references.html#ref-Porteus1975" role="doc-biblioref">1975</a>)</span> also describes transformations of the dynamics which preserve the optimal policy.</p>
<p><a href="#cor-reward-shaping-discounted">Corollary&nbsp;<span>9.2</span></a> was also re-established by <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span>, who aslo provided a partial converse. The results of <span class="citation" data-cites="Porteus1975">Porteus (<a href="../references.html#ref-Porteus1975" role="doc-biblioref">1975</a>)</span> and <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span> were restricted to time-homogeneous potential functions. The generalization to time-varying potential functions was presented in <span class="citation" data-cites="Devlin2012">Devlin and Kudenko (<a href="../references.html#ref-Devlin2012" role="doc-biblioref">2012</a>)</span>.</p>
<p>The partial converse of <a href="#cor-reward-shaping">Corollary&nbsp;<span>9.1</span></a> established by <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span> states that the shaping presented in <a href="#thm-reward-shaping">Theorem&nbsp;<span>9.1</span></a> is the <em>only</em> additive cost transformation that that preserves the set of optimal policy. However, this converse was derived under the assumption that the transition dynamics are <em>complete</em> (see <span class="citation" data-cites="Ng1999">Ng et al. (<a href="../references.html#ref-Ng1999" role="doc-biblioref">1999</a>)</span>). A similar converse under a weaker set of assumptions on the transition dynamics is established in <span class="citation" data-cites="Jenner2022">Jenner et al. (<a href="../references.html#ref-Jenner2022" role="doc-biblioref">2022</a>)</span>.</p>
<p>For a discussion on practical considerations in using reward shaping in reinforcement learning, see <span class="citation" data-cites="Grzes2009">Grzes and Kudenko (<a href="../references.html#ref-Grzes2009" role="doc-biblioref">2009</a>)</span> and <span class="citation" data-cites="Devlin2014">Devlin (<a href="../references.html#ref-Devlin2014" role="doc-biblioref">2014</a>)</span>. As a counter-point, <span class="citation" data-cites="Wiewiora2003">Wiewiora (<a href="../references.html#ref-Wiewiora2003" role="doc-biblioref">2003</a>)</span> shows that the advantages of reward shaping can also be achieved by simply adding the potential function to the <span class="math inline">\(Q\)</span>-function initialization.</p>
<hr>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-Devlin2014" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Devlin, S.</span> 2014. Potential based reward shaping tutorial. Available at: <a href="http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf">http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf</a>.
</div>
<div id="ref-Devlin2012" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Devlin, S. and Kudenko, D.</span> 2012. Dynamic potential-based reward shaping. <em>Proceedings of the 11th international conference on autonomous agents and multiagent systems</em>, International Foundation for Autonomous Agents; Multiagent Systems, 433–440.
</div>
<div id="ref-Grzes2009" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Grzes, M. and Kudenko, D.</span> 2009. Theoretical and empirical analysis of reward shaping in reinforcement learning. <em>International conference on machine learning and applications</em>, 337–344. DOI: <a href="https://doi.org/10.1109/ICMLA.2009.33">10.1109/ICMLA.2009.33</a>.
</div>
<div id="ref-Jenner2022" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Jenner, E., Hoof, H. van, and Gleave, A.</span> 2022. Calculus on MDPs: Potential shaping as a gradient. Available at: <a href="https://arxiv.org/abs/2208.09570v1">https://arxiv.org/abs/2208.09570v1</a>.
</div>
<div id="ref-Ng1999" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Ng, A.Y., Harada, D., and Russell, S.</span> 1999. Policy invariance under reward transformations: Theory and application to reward shaping. <em>ICML</em>, 278–287. Available at: <a href="http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf">http://aima.eecs.berkeley.edu/~russell/papers/icml99-shaping.pdf</a>.
</div>
<div id="ref-Porteus1975" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Porteus, E.L.</span> 1975. Bounds and transformations for discounted finite markov decision chains. <em>Operations Research</em> <em>23</em>, 4, 761–784. DOI: <a href="https://doi.org/10.1287/opre.23.4.761">10.1287/opre.23.4.761</a>.
</div>
<div id="ref-Skinner1938" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Skinner, B.F.</span> 1938. <em>Behavior of organisms</em>. Appleton-Century.
</div>
<div id="ref-Wiewiora2003" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Wiewiora, E.</span> 2003. Potential-based shaping and q-value initialization are equivalent. <em>Journal of Artificial Intelligence Research</em> <em>19</em>, 1, 205–208.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../mdps/power-delay-tradeoff.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../mdps/inf-horizon.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>